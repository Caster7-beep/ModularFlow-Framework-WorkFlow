# SmartTavern LLMæ¡¥æ¥æ¨¡å—

æœ¬æ¨¡å—ä¸ºSmartTavernæä¾›ä¸é€šç”¨LLM APIæ¨¡å—çš„æ¡¥æ¥åŠŸèƒ½ï¼Œè´Ÿè´£ç®¡ç†APIé…ç½®ã€è°ƒç”¨é€šç”¨LLM APIï¼Œå¹¶å¤„ç†SmartTavernç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ”— **APIæ¡¥æ¥**: è¿æ¥SmartTavernä¸é€šç”¨LLM APIæ¨¡å—
- âš™ï¸ **é…ç½®ç®¡ç†**: ç®¡ç†å¤šä¸ªAPIæä¾›å•†çš„é…ç½®å’Œåˆ‡æ¢
- ğŸ“Š **ç»Ÿè®¡è·Ÿè¸ª**: ç»´æŠ¤APIä½¿ç”¨ç»Ÿè®¡å’Œç›‘æ§
- ğŸ”„ **æ™ºèƒ½ç¼“å­˜**: ç¼“å­˜APIç®¡ç†å™¨å®ä¾‹ä»¥æé«˜æ€§èƒ½
- ğŸ“ **ç»Ÿä¸€æ¥å£**: æä¾›æ ‡å‡†åŒ–çš„LLM APIè°ƒç”¨æ¥å£

## æ¶æ„è®¾è®¡

```
SmartTavernæ¨¡å— --> LLMæ¡¥æ¥æ¨¡å— --> é€šç”¨LLM APIæ¨¡å— --> APIæä¾›å•†
     â†‘                 â†‘                    â†‘              â†‘
  ä¸šåŠ¡é€»è¾‘           é…ç½®ç®¡ç†            APIè°ƒç”¨         å®é™…æœåŠ¡
```

## æä¾›çš„å‡½æ•°

### æ ¸å¿ƒAPIè°ƒç”¨

#### `api.call(messages, stream, model, max_tokens, temperature, provider, **kwargs)`
ä¸»è¦çš„APIè°ƒç”¨å‡½æ•°
```python
# è°ƒç”¨ç¤ºä¾‹
response = api.call([
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
    {"role": "user", "content": "ä½ å¥½"}
], model="gpt-4", temperature=0.7)
```

#### `api.call_streaming(messages, provider, **kwargs)`
æµå¼APIè°ƒç”¨çš„ä¾¿æ·å‡½æ•°
```python
# æµå¼è°ƒç”¨ç¤ºä¾‹
response = api.call_streaming([
    {"role": "user", "content": "å†™ä¸€ä¸ªé•¿æ•…äº‹"}
])
```

### æä¾›å•†ç®¡ç†

#### `api.get_providers()`
è·å–æ‰€æœ‰APIæä¾›å•†ä¿¡æ¯
```python
providers = api.get_providers()
# è¿”å›: {"providers": [{"name": "openai", "config": {...}}, ...]}
```

#### `api.set_provider(provider_name)`
è®¾ç½®æ´»åŠ¨çš„APIæä¾›å•†
```python
result = api.set_provider("anthropic")
# è¿”å›: {"success": True, "message": "å·²åˆ‡æ¢åˆ°æä¾›å•†: anthropic"}
```

#### `api.configure_provider(provider_name, api_key, base_url, models, enabled)`
é…ç½®APIæä¾›å•†
```python
result = api.configure_provider(
    "openai",
    "sk-...",
    "https://api.openai.com/v1",
    ["gpt-4", "gpt-3.5-turbo"]
)
```

### è¾…åŠ©åŠŸèƒ½

#### `api.get_models(provider)`
è·å–æŒ‡å®šæä¾›å•†çš„å¯ç”¨æ¨¡å‹
```python
models = api.get_models("openai")
# è¿”å›: {"models": ["gpt-4", "gpt-3.5-turbo", ...]}
```

#### `api.get_stats()`
è·å–APIä½¿ç”¨ç»Ÿè®¡
```python
stats = api.get_stats()
# è¿”å›ç»Ÿè®¡ä¿¡æ¯
```

#### `api.reset_stats()`
é‡ç½®APIä½¿ç”¨ç»Ÿè®¡
```python
result = api.reset_stats()
```

## é…ç½®è¦æ±‚

æ¡¥æ¥æ¨¡å—ä¾èµ–SmartTavernçš„å…¨å±€é…ç½®ï¼Œéœ€è¦ä»¥ä¸‹é…ç½®ç»“æ„ï¼š

```python
# shared/SmartTavern/globals.py
api_providers = {
    "openai": {
        "name": "OpenAI",
        "base_url": "https://api.openai.com/v1", 
        "api_key": "sk-...",
        "models": ["gpt-4", "gpt-3.5-turbo"],
        "enabled": True
    },
    # å…¶ä»–æä¾›å•†...
}

active_api_provider = "openai"

llm_stats = {
    "total_requests": 0,
    "successful_requests": 0,
    "failed_requests": 0,
    "total_tokens_used": 0,
    "last_request_time": None,
    "average_response_time": 0.0
}

api_request_config = {
    "timeout": 60,
    "enable_logging": False
}
```

## æ ¸å¿ƒåŠŸèƒ½

æœ¬æ¨¡å—æä¾›å®Œæ•´çš„LLM APIç®¡ç†åŠŸèƒ½ï¼š

- âœ… `api.call()` - ä¸»è¦APIè°ƒç”¨æ¥å£
- âœ… `api.call_streaming()` - æµå¼APIè°ƒç”¨æ¥å£
- âœ… `api.get_providers()` - è·å–æä¾›å•†ä¿¡æ¯
- âœ… `api.set_provider()` - åˆ‡æ¢æ´»åŠ¨æä¾›å•†
- âœ… `api.configure_provider()` - é…ç½®æä¾›å•†å‚æ•°
- âœ… `api.get_stats()` - è·å–ä½¿ç”¨ç»Ÿè®¡
- âœ… `api.reset_stats()` - é‡ç½®ç»Ÿè®¡æ•°æ®
- ğŸ†• `api.get_models()` - è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

## æ€§èƒ½ä¼˜åŒ–

- **ç®¡ç†å™¨ç¼“å­˜**: APIç®¡ç†å™¨å®ä¾‹ä¼šè¢«ç¼“å­˜ï¼Œé¿å…é‡å¤åˆ›å»º
- **æ‡’åŠ è½½**: åªåœ¨éœ€è¦æ—¶åˆ›å»ºAPIç®¡ç†å™¨
- **é…ç½®å˜æ›´æ£€æµ‹**: é…ç½®å˜æ›´æ—¶è‡ªåŠ¨æ¸…ç†ç¼“å­˜

## é”™è¯¯å¤„ç†

æ¡¥æ¥æ¨¡å—æä¾›å¤šå±‚é”™è¯¯å¤„ç†ï¼š

1. **é…ç½®éªŒè¯**: æ£€æŸ¥APIæä¾›å•†é…ç½®çš„å®Œæ•´æ€§
2. **ç®¡ç†å™¨åˆ›å»º**: å¤„ç†APIç®¡ç†å™¨åˆ›å»ºå¤±è´¥
3. **APIè°ƒç”¨**: ä¼ é€’é€šç”¨LLMæ¨¡å—çš„é”™è¯¯ä¿¡æ¯
4. **ç»Ÿè®¡æ›´æ–°**: å®‰å…¨çš„ç»Ÿè®¡ä¿¡æ¯æ›´æ–°

## ä½¿ç”¨ç¤ºä¾‹

```python
from core.services import UnifiedServiceManager

# åˆå§‹åŒ–æœåŠ¡ç®¡ç†å™¨ï¼ˆä¼šè‡ªåŠ¨æ³¨å†Œæ¡¥æ¥æ¨¡å—çš„å‡½æ•°ï¼‰
service_manager = UnifiedServiceManager()

# è°ƒç”¨API
response = service_manager.call_function("api.call", {
    "messages": [
        {"role": "user", "content": "Hello"}
    ],
    "model": "gpt-4",
    "temperature": 0.7
})

if response["response"]["success"]:
    print(response["response"]["content"])
else:
    print(f"é”™è¯¯: {response['response']['error']}")
```

## ä¾èµ–å…³ç³»

- **é€šç”¨LLM APIæ¨¡å—**: æ ¸å¿ƒAPIè°ƒç”¨åŠŸèƒ½
- **SmartTavernå…¨å±€é…ç½®**: é…ç½®æ•°æ®æ¥æº
- **æ ¸å¿ƒæœåŠ¡**: å‡½æ•°æ³¨å†Œå’Œå…¨å±€å˜é‡è®¿é—®

## ç»´æŠ¤è¯´æ˜

- ä¿®æ”¹APIæä¾›å•†æ”¯æŒæ—¶ï¼Œåªéœ€æ›´æ–°é€šç”¨LLM APIæ¨¡å—
- æ–°å¢ä¸šåŠ¡åŠŸèƒ½æ—¶ï¼Œåœ¨æ­¤æ¡¥æ¥æ¨¡å—ä¸­å®ç°
- é…ç½®å˜æ›´æ—¶ï¼Œè®°å¾—è°ƒç”¨`clear_api_managers()`æ¸…ç†ç¼“å­˜