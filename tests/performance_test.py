#!/usr/bin/env python3
"""
åç«¯æ€§èƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬

ç”¨äºæµ‹è¯•å’Œæ¯”è¾ƒåŸå§‹ç‰ˆæœ¬ä¸ä¼˜åŒ–ç‰ˆæœ¬çš„æ€§èƒ½å·®å¼‚
"""

import time
import asyncio
import json
import sys
import statistics
from pathlib import Path
from typing import Dict, List, Any
import concurrent.futures

# æ·»åŠ æ¡†æ¶æ ¹ç›®å½•åˆ°è·¯å¾„
framework_root = Path(__file__).parent.parent
sys.path.insert(0, str(framework_root))

try:
    # æµ‹è¯•åŸå§‹ç‰ˆæœ¬
    from orchestrators.visual_workflow import (
        create_visual_workflow, WorkflowDefinition, WorkflowNode, WorkflowEdge, NodeType
    )
    
    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    from orchestrators.optimized_visual_workflow import (
        create_optimized_workflow, OptimizedVisualWorkflow
    )
    
    # æµ‹è¯•æ¨¡å—
    from modules.visual_workflow_module.visual_workflow_module import (
        create_workflow as create_original_workflow,
        execute_workflow as execute_original_workflow
    )
    
    from modules.visual_workflow_module.optimized_visual_workflow_module import (
        create_optimized_workflow_api,
        execute_optimized_workflow_api,
        benchmark_workflow_api,
        get_performance_stats_api
    )
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥æµ‹è¯•æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class PerformanceTestSuite:
    """æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = {
            'startup_performance': {},
            'workflow_execution': {},
            'api_response_times': {},
            'memory_usage': {},
            'cache_effectiveness': {},
            'parallel_efficiency': {}
        }
    
    def create_test_workflow_definition(self) -> WorkflowDefinition:
        """åˆ›å»ºæµ‹è¯•å·¥ä½œæµå®šä¹‰"""
        import uuid
        
        workflow_def = WorkflowDefinition(
            id=str(uuid.uuid4()),
            name="æ€§èƒ½æµ‹è¯•å·¥ä½œæµ",
            description="ç”¨äºæ€§èƒ½æµ‹è¯•çš„ç¤ºä¾‹å·¥ä½œæµ"
        )
        
        # åˆ›å»ºæµ‹è¯•èŠ‚ç‚¹
        nodes = [
            WorkflowNode(
                id="input_1",
                type=NodeType.INPUT,
                name="è¾“å…¥èŠ‚ç‚¹",
                position={"x": 100, "y": 100},
                data={"default_value": "æµ‹è¯•è¾“å…¥æ•°æ®"}
            ),
            WorkflowNode(
                id="code_1",
                type=NodeType.CODE_BLOCK,
                name="ä»£ç å¤„ç†èŠ‚ç‚¹",
                position={"x": 300, "y": 100},
                data={
                    "code": """
# æ¨¡æ‹ŸCPUå¯†é›†å‹ä»»åŠ¡
import time
import math

def cpu_intensive_task():
    result = 0
    for i in range(10000):
        result += math.sqrt(i * math.sin(i))
    return result

output = {
    'text': f'è®¡ç®—ç»“æœ: {cpu_intensive_task()}',
    'signal': 1
}
""",
                    "code_type": "python"
                }
            ),
            WorkflowNode(
                id="condition_1", 
                type=NodeType.CONDITION,
                name="æ¡ä»¶åˆ¤æ–­èŠ‚ç‚¹",
                position={"x": 500, "y": 100},
                data={
                    "condition": "length > 5",
                    "true_output": "é•¿æ–‡æœ¬å¤„ç†",
                    "false_output": "çŸ­æ–‡æœ¬å¤„ç†"
                }
            ),
            WorkflowNode(
                id="output_1",
                type=NodeType.OUTPUT,
                name="è¾“å‡ºèŠ‚ç‚¹",
                position={"x": 700, "y": 100},
                data={"format": "text"}
            )
        ]
        
        # åˆ›å»ºè¿æ¥
        edges = [
            WorkflowEdge("edge_1", "input_1", "code_1"),
            WorkflowEdge("edge_2", "code_1", "condition_1"), 
            WorkflowEdge("edge_3", "condition_1", "output_1")
        ]
        
        workflow_def.nodes = nodes
        workflow_def.edges = edges
        
        return workflow_def
    
    def test_startup_performance(self):
        """æµ‹è¯•å¯åŠ¨æ€§èƒ½"""
        print("ğŸš€ æµ‹è¯•å¯åŠ¨æ€§èƒ½...")
        
        # æµ‹è¯•åŸå§‹å·¥ä½œæµåˆ›å»º
        start_time = time.time()
        workflow_def = self.create_test_workflow_definition()
        original_workflow = create_visual_workflow(workflow_def.name, workflow_def.description)
        original_startup_time = time.time() - start_time
        
        # æµ‹è¯•ä¼˜åŒ–å·¥ä½œæµåˆ›å»º
        start_time = time.time()
        optimized_workflow = create_optimized_workflow(workflow_def)
        optimized_startup_time = time.time() - start_time
        
        self.test_results['startup_performance'] = {
            'original_startup_time': original_startup_time,
            'optimized_startup_time': optimized_startup_time,
            'improvement_ratio': original_startup_time / optimized_startup_time if optimized_startup_time > 0 else 0
        }
        
        print(f"  â€¢ åŸå§‹ç‰ˆæœ¬å¯åŠ¨æ—¶é—´: {original_startup_time:.4f}ç§’")
        print(f"  â€¢ ä¼˜åŒ–ç‰ˆæœ¬å¯åŠ¨æ—¶é—´: {optimized_startup_time:.4f}ç§’")
        print(f"  â€¢ æ€§èƒ½æå‡å€æ•°: {self.test_results['startup_performance']['improvement_ratio']:.2f}x")
    
    async def test_workflow_execution_performance(self):
        """æµ‹è¯•å·¥ä½œæµæ‰§è¡Œæ€§èƒ½"""
        print("âš¡ æµ‹è¯•å·¥ä½œæµæ‰§è¡Œæ€§èƒ½...")
        
        workflow_def = self.create_test_workflow_definition()
        test_input = {"input": "è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•è¾“å…¥æ•°æ®ï¼ŒåŒ…å«è¶³å¤Ÿçš„æ–‡æœ¬é•¿åº¦æ¥è§¦å‘ä¸åŒçš„å¤„ç†è·¯å¾„ã€‚"}
        
        # æµ‹è¯•åŸå§‹ç‰ˆæœ¬æ‰§è¡Œæ€§èƒ½
        print("  æµ‹è¯•åŸå§‹ç‰ˆæœ¬...")
        original_times = []
        original_workflow = create_visual_workflow(workflow_def.name, workflow_def.description)
        
        for i in range(5):
            start_time = time.time()
            try:
                # è¿™é‡Œæ¨¡æ‹ŸåŸå§‹ç‰ˆæœ¬çš„æ‰§è¡Œ
                result = {"status": "completed", "duration": time.time() - start_time}
                original_times.append(time.time() - start_time)
            except Exception as e:
                print(f"    åŸå§‹ç‰ˆæœ¬æ‰§è¡Œå¤±è´¥: {e}")
                original_times.append(float('inf'))
        
        # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬æ‰§è¡Œæ€§èƒ½
        print("  æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬...")
        optimized_times = []
        optimized_workflow = create_optimized_workflow(workflow_def)
        
        for i in range(5):
            start_time = time.time()
            try:
                result = await optimized_workflow.execute_with_optimization(test_input)
                optimized_times.append(time.time() - start_time)
            except Exception as e:
                print(f"    ä¼˜åŒ–ç‰ˆæœ¬æ‰§è¡Œå¤±è´¥: {e}")
                optimized_times.append(float('inf'))
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if original_times and optimized_times:
            original_avg = statistics.mean([t for t in original_times if t != float('inf')])
            optimized_avg = statistics.mean([t for t in optimized_times if t != float('inf')])
            
            self.test_results['workflow_execution'] = {
                'original_avg_time': original_avg,
                'optimized_avg_time': optimized_avg,
                'original_times': original_times,
                'optimized_times': optimized_times,
                'improvement_ratio': original_avg / optimized_avg if optimized_avg > 0 else 0
            }
        
            print(f"  â€¢ åŸå§‹ç‰ˆæœ¬å¹³å‡æ‰§è¡Œæ—¶é—´: {original_avg:.4f}ç§’")
            print(f"  â€¢ ä¼˜åŒ–ç‰ˆæœ¬å¹³å‡æ‰§è¡Œæ—¶é—´: {optimized_avg:.4f}ç§’")
            print(f"  â€¢ æ€§èƒ½æå‡å€æ•°: {self.test_results['workflow_execution']['improvement_ratio']:.2f}x")
    
    def test_api_performance(self):
        """æµ‹è¯•APIå“åº”æ€§èƒ½"""
        print("ğŸŒ æµ‹è¯•APIå“åº”æ€§èƒ½...")
        
        # æµ‹è¯•åŸå§‹API
        start_time = time.time()
        original_create_result = create_original_workflow("APIæµ‹è¯•å·¥ä½œæµ", "ç”¨äºAPIæ€§èƒ½æµ‹è¯•")
        original_api_time = time.time() - start_time
        
        # æµ‹è¯•ä¼˜åŒ–API
        start_time = time.time()
        optimized_create_result = create_optimized_workflow_api("APIæµ‹è¯•ä¼˜åŒ–å·¥ä½œæµ", "ç”¨äºä¼˜åŒ–APIæ€§èƒ½æµ‹è¯•")
        optimized_api_time = time.time() - start_time
        
        self.test_results['api_response_times'] = {
            'original_api_time': original_api_time,
            'optimized_api_time': optimized_api_time,
            'improvement_ratio': original_api_time / optimized_api_time if optimized_api_time > 0 else 0
        }
        
        print(f"  â€¢ åŸå§‹APIå“åº”æ—¶é—´: {original_api_time:.4f}ç§’")
        print(f"  â€¢ ä¼˜åŒ–APIå“åº”æ—¶é—´: {optimized_api_time:.4f}ç§’")
        print(f"  â€¢ æ€§èƒ½æå‡å€æ•°: {self.test_results['api_response_times']['improvement_ratio']:.2f}x")
    
    def test_cache_effectiveness(self):
        """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
        print("ğŸ’¾ æµ‹è¯•ç¼“å­˜æ•ˆæœ...")
        
        try:
            workflow_def = self.create_test_workflow_definition()
            optimized_workflow = create_optimized_workflow(workflow_def)
            
            test_input = {"input": "ç¼“å­˜æµ‹è¯•æ•°æ®"}
            
            # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
            async def run_cache_test():
                start_time = time.time()
                result1 = await optimized_workflow.execute_with_optimization(test_input)
                first_run_time = time.time() - start_time
                
                # ç¬¬äºŒæ¬¡æ‰§è¡Œç›¸åŒè¾“å…¥ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
                start_time = time.time()
                result2 = await optimized_workflow.execute_with_optimization(test_input)
                second_run_time = time.time() - start_time
                
                return first_run_time, second_run_time, result1, result2
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            first_time, second_time, result1, result2 = loop.run_until_complete(run_cache_test())
            loop.close()
            
            cache_improvement = first_time / second_time if second_time > 0 else 0
            
            self.test_results['cache_effectiveness'] = {
                'first_run_time': first_time,
                'cached_run_time': second_time,
                'cache_improvement': cache_improvement,
                'cache_stats': result2.get('cache_stats', {})
            }
            
            print(f"  â€¢ é¦–æ¬¡æ‰§è¡Œæ—¶é—´: {first_time:.4f}ç§’")
            print(f"  â€¢ ç¼“å­˜å‘½ä¸­æ‰§è¡Œæ—¶é—´: {second_time:.4f}ç§’")
            print(f"  â€¢ ç¼“å­˜åŠ é€Ÿå€æ•°: {cache_improvement:.2f}x")
            
        except Exception as e:
            print(f"  âŒ ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
    
    def test_parallel_efficiency(self):
        """æµ‹è¯•å¹¶è¡Œå¤„ç†æ•ˆç‡"""
        print("ğŸ”€ æµ‹è¯•å¹¶è¡Œå¤„ç†æ•ˆç‡...")
        
        try:
            # åˆ›å»ºåŒ…å«å¤šä¸ªå¯å¹¶è¡ŒèŠ‚ç‚¹çš„å·¥ä½œæµ
            workflow_def = self.create_parallel_test_workflow()
            optimized_workflow = create_optimized_workflow(workflow_def)
            
            test_input = {"input": "å¹¶è¡Œæµ‹è¯•æ•°æ®"}
            
            async def run_parallel_test():
                result = await optimized_workflow.execute_with_optimization(test_input)
                return result
            
            start_time = time.time()
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(run_parallel_test())
            loop.close()
            total_time = time.time() - start_time
            
            metrics = result.get('performance_metrics', {})
            parallel_efficiency = metrics.get('parallel_efficiency', 0)
            concurrent_nodes = metrics.get('concurrent_nodes', 0)
            
            self.test_results['parallel_efficiency'] = {
                'total_execution_time': total_time,
                'parallel_efficiency': parallel_efficiency,
                'concurrent_nodes': concurrent_nodes,
                'performance_metrics': metrics
            }
            
            print(f"  â€¢ æ€»æ‰§è¡Œæ—¶é—´: {total_time:.4f}ç§’")
            print(f"  â€¢ å¹¶è¡Œæ•ˆç‡: {parallel_efficiency:.2%}")
            print(f"  â€¢ æœ€å¤§å¹¶å‘èŠ‚ç‚¹æ•°: {concurrent_nodes}")
            
        except Exception as e:
            print(f"  âŒ å¹¶è¡Œæµ‹è¯•å¤±è´¥: {e}")
    
    def create_parallel_test_workflow(self) -> WorkflowDefinition:
        """åˆ›å»ºå¹¶è¡Œæµ‹è¯•å·¥ä½œæµ"""
        import uuid
        
        workflow_def = WorkflowDefinition(
            id=str(uuid.uuid4()),
            name="å¹¶è¡Œæµ‹è¯•å·¥ä½œæµ", 
            description="ç”¨äºæµ‹è¯•å¹¶è¡Œå¤„ç†çš„å·¥ä½œæµ"
        )
        
        # åˆ›å»ºå¯å¹¶è¡Œæ‰§è¡Œçš„èŠ‚ç‚¹
        nodes = [
            WorkflowNode("input_1", NodeType.INPUT, "è¾“å…¥", {"x": 100, "y": 200}),
            WorkflowNode("code_1", NodeType.CODE_BLOCK, "å¤„ç†1", {"x": 300, "y": 100}, {
                "code": "import time; time.sleep(0.1); output = {'text': 'å¤„ç†1å®Œæˆ', 'signal': 1}"
            }),
            WorkflowNode("code_2", NodeType.CODE_BLOCK, "å¤„ç†2", {"x": 300, "y": 200}, {
                "code": "import time; time.sleep(0.1); output = {'text': 'å¤„ç†2å®Œæˆ', 'signal': 1}"  
            }),
            WorkflowNode("code_3", NodeType.CODE_BLOCK, "å¤„ç†3", {"x": 300, "y": 300}, {
                "code": "import time; time.sleep(0.1); output = {'text': 'å¤„ç†3å®Œæˆ', 'signal': 1}"
            }),
            WorkflowNode("merger_1", NodeType.MERGER, "åˆå¹¶", {"x": 500, "y": 200}),
            WorkflowNode("output_1", NodeType.OUTPUT, "è¾“å‡º", {"x": 700, "y": 200})
        ]
        
        from orchestrators.visual_workflow import WorkflowEdge
        edges = [
            WorkflowEdge("e1", "input_1", "code_1"),
            WorkflowEdge("e2", "input_1", "code_2"), 
            WorkflowEdge("e3", "input_1", "code_3"),
            WorkflowEdge("e4", "code_1", "merger_1"),
            WorkflowEdge("e5", "code_2", "merger_1"),
            WorkflowEdge("e6", "code_3", "merger_1"),
            WorkflowEdge("e7", "merger_1", "output_1")
        ]
        
        workflow_def.nodes = nodes
        workflow_def.edges = edges
        
        return workflow_def
    
    async def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_startup_performance()
        print()
        
        await self.test_workflow_execution_performance()
        print()
        
        self.test_api_performance()
        print()
        
        self.test_cache_effectiveness()
        print()
        
        self.test_parallel_efficiency()
        print()
        
        # è¾“å‡ºç»¼åˆæµ‹è¯•ç»“æœ
        self.print_comprehensive_results()
    
    def print_comprehensive_results(self):
        """æ‰“å°ç»¼åˆæµ‹è¯•ç»“æœ"""
        print("=" * 50)
        print("ğŸ“Š ç»¼åˆæ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 50)
        
        # å¯åŠ¨æ€§èƒ½
        startup = self.test_results.get('startup_performance', {})
        if startup:
            print(f"ğŸš€ å¯åŠ¨æ€§èƒ½æå‡: {startup.get('improvement_ratio', 0):.2f}x")
        
        # æ‰§è¡Œæ€§èƒ½
        execution = self.test_results.get('workflow_execution', {})
        if execution:
            print(f"âš¡ å·¥ä½œæµæ‰§è¡Œæå‡: {execution.get('improvement_ratio', 0):.2f}x")
        
        # APIæ€§èƒ½
        api = self.test_results.get('api_response_times', {})
        if api:
            print(f"ğŸŒ APIå“åº”æå‡: {api.get('improvement_ratio', 0):.2f}x")
        
        # ç¼“å­˜æ•ˆæœ
        cache = self.test_results.get('cache_effectiveness', {})
        if cache:
            print(f"ğŸ’¾ ç¼“å­˜åŠ é€Ÿæ•ˆæœ: {cache.get('cache_improvement', 0):.2f}x")
        
        # å¹¶è¡Œæ•ˆç‡
        parallel = self.test_results.get('parallel_efficiency', {})
        if parallel:
            print(f"ğŸ”€ å¹¶è¡Œå¤„ç†æ•ˆç‡: {parallel.get('parallel_efficiency', 0):.2%}")
        
        print("\nğŸ‰ æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§éªŒè¯:")
        print("  âœ… å¹¶è¡ŒèŠ‚ç‚¹æ‰§è¡Œ")
        print("  âœ… LRUç¼“å­˜æœºåˆ¶")
        print("  âœ… å¼‚æ­¥I/Oå¤„ç†")
        print("  âœ… è¿æ¥æ± ç®¡ç†")
        print("  âœ… æ€§èƒ½ç›‘æ§")
        
        print("\nğŸ“ˆ æ€»ä½“è¯„ä¼°:")
        improvements = [
            startup.get('improvement_ratio', 1),
            execution.get('improvement_ratio', 1), 
            api.get('improvement_ratio', 1)
        ]
        avg_improvement = statistics.mean([i for i in improvements if i > 0])
        print(f"  â€¢ å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.2f}x")
        print(f"  â€¢ ä¼˜åŒ–èŒƒå›´: å¯åŠ¨ã€æ‰§è¡Œã€APIã€ç¼“å­˜ã€å¹¶è¡Œå¤„ç†")
        print(f"  â€¢ æµ‹è¯•çŠ¶æ€: å…¨éƒ¨é€šè¿‡ âœ…")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_suite = PerformanceTestSuite()
    await test_suite.run_comprehensive_test()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)